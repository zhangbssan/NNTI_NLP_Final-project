{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bengali.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fND9fMxuSCsi"
      },
      "source": [
        "# **Task 2 - Sentiment Classifier & Transfer Learning (10 points)**\n",
        "## **Imports** \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3MIG5VsqDLf"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "torch.manual_seed(10)\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn as sk\n",
        "import re\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from matplotlib import pyplot as plt\n",
        "import nltk\n",
        "import torch.nn as  nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQbN9otHM-SU",
        "outputId": "09746c8e-a90b-4648-9d31-5b7e8891dca1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0o7a4qkNg6h"
      },
      "source": [
        "import modelinput"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1qPhGs82b-O"
      },
      "source": [
        "## **2.2.1 Get the data (0.5 points)**\n",
        "The downloaded file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "veCv7VsAowag",
        "outputId": "f0125025-053b-4408-ecd6-094da79e0731"
      },
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()\n",
        "data = pd.read_csv(\"bengali_hatespeech.csv\",sep=',')\n",
        "data1 = data.iloc[0:19000,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73e10a30-ca7c-4ffc-88de-aac2fb48bdc4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-73e10a30-ca7c-4ffc-88de-aac2fb48bdc4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving bengali_hatespeech.csv to bengali_hatespeech.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zCtLO8p5au_"
      },
      "source": [
        "#Split off a part of the Bengali corpus such that it roughly equals the Hindi corpus in size and distribution of classes\n",
        "from sklearn.model_selection import train_test_split\n",
        "x, y = data1['sentence'], data1['hate']\n",
        "X_TRAIN,x_test,Y_TRAIN,y_test=train_test_split(x,y,train_size=0.25,random_state=123)\n",
        "X_TRAIN = X_TRAIN.values #roughtly the same number of sentences\n",
        "Y_TRAIN = Y_TRAIN.values #roughtly the same number of labels\n",
        "result = pd.value_counts(Y_TRAIN)\n",
        "#print(Y_TRAIN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnpVZczLFEc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ab5c57-fedd-4129-d519-e9e661ebf676"
      },
      "source": [
        "# using a small development set\n",
        "x_train_dev=X_TRAIN[1900:3000]\n",
        "y_train = Y_TRAIN[1900:3000]\n",
        "result = pd.value_counts(y_train)\n",
        "print(result)\n",
        "print(len(x_train_dev))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    565\n",
            "0    535\n",
            "dtype: int64\n",
            "1100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX2DCfm0JhXg"
      },
      "source": [
        "2.2.2clean the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "12UrwLSLEPVt",
        "outputId": "8bde8662-27f0-42be-e7a9-5ec1b00751cd"
      },
      "source": [
        "#clean the data\n",
        "uploaded = files.upload()\n",
        "stopwords = pd.read_csv('stopwords-bn.txt',header=None)\n",
        "def clean_the_data(data):\n",
        "  new_list=[]\n",
        "  punc=r'''!()-[]{};:'\"\\,<>./?@#$%^&*_“~'''\n",
        "  stop_words=stopwords[0].tolist()\n",
        "  for i in range(0,len(data)):\n",
        "    # Punctuations removal\n",
        "    new=' '.join(word for word in data[i].split() if word[0] not in punc)\n",
        "    new = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", new).split())\n",
        "    new = ' '.join(re.sub(r\"\\b\\d+\\b\", \" \", new).split())\n",
        "    new = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=\\#\\%\\…\\\\u200d\\।।]\", \" \", new).split())\n",
        "    new = ' '.join(re.sub(\"[\\U0001F600-\\U0001F64F]\",\" \",new).split()) # emotions\n",
        "    new = ' '.join(re.sub(\"[\\U0001F300-\\U0001F5FF]\",\" \",new).split()) # symbols & pictographs                           \n",
        "    new = ' '.join(re.sub(\"[\\U0001F680-\\U0001F6FF]\",\" \",new).split()) # transport & map symbols                         \n",
        "    new = ' '.join(re.sub(\"[\\U0001F1E0-\\U0001F1FF]\",\" \",new).split()) # flags (iOS)  \n",
        "    new = ' '.join(re.sub(\"[\\U00002702-\\U000027B0]\",\" \",new).split())  \n",
        "    new = ' '.join(re.sub(\"[\\U000024C2-\\U0001F251]\",\" \",new).split()) \n",
        "    new = ' '.join(re.sub(\"[\\U00001F92C]\",\" \",new).split())                                                \n",
        "    # Converting into lowercase\n",
        "    new= new.lower()\n",
        "    # Removing stop words\n",
        "    new=' '.join(word for word in new.split() if word not in stop_words)\n",
        "    # Appending to the text list\n",
        "    new_list.append(new)\n",
        "  return new_list\n",
        "\n",
        "new_list = clean_the_data(x_train_dev)\n",
        "#print(new_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-df52b30c-7882-4042-8605-59223bd4ac50\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-df52b30c-7882-4042-8605-59223bd4ac50\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving stopwords-bn.txt to stopwords-bn.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JHzrXoNIWtT",
        "outputId": "f595a72d-8fb1-4ac6-da5a-eaee61f09c19"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDFtdqfIIYmw"
      },
      "source": [
        "# Tokenizes each sentence by implementing the nltk tool\n",
        "new_list_new = [nltk.tokenize.word_tokenize(x) for x in new_list]\n",
        "#print(new_list_new[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEJRGjxcJqtd"
      },
      "source": [
        "2.2.3Build the vocabulary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH9HqPb7jAbi"
      },
      "source": [
        "V=modelinput.vocabulary(new_list_new)\n",
        "#print(V)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFmpRB1PNtqx"
      },
      "source": [
        "returns one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-LXbE2bN3yt"
      },
      "source": [
        "def word_to_one_hot(word):\n",
        "  words = V.keys()\n",
        "  str_to_int = dict((c, i) for i, c in enumerate(words))\n",
        "  integer_encoded = [str_to_int[string] for string in [word]]\n",
        "  # one hot encode\n",
        "  onehot_encoded = []\n",
        "  for value in integer_encoded:\n",
        "\t     letter = [0 for _ in range(len(V))]\n",
        "\t     letter[value] = 1\n",
        "\t     onehot_encoded.append(letter)\n",
        "  #onehot_encoded.long()\n",
        "  return onehot_encoded\n",
        "  pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyPGZt1URdkw"
      },
      "source": [
        "2.2.4Subsampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2_4s9mURc0q"
      },
      "source": [
        "Words = {}\n",
        "i=0\n",
        "for s in range(len(new_list_new)):\n",
        "  n=new_list_new[s]\n",
        "  for y in range(len(n)):\n",
        "    w=new_list_new[s][y]\n",
        "    Words[w] = i\n",
        "    i+=1\n",
        "    y+=1\n",
        "  s+=1\n",
        "W2=list(Words)\n",
        "def sampling_prob(word):\n",
        "    frac = W2.count(word)/len(W2)\n",
        "    prob = (np.sqrt(frac/0.000001) + 1) * (0.000001/frac)\n",
        "    return prob\n",
        "    pass\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSKzWbWlXHAb"
      },
      "source": [
        " 2.2.5Skip-Grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT8AiU5eXFyL"
      },
      "source": [
        "#from bndatapro import get_target_context\n",
        "def get_target_context(sentence):\n",
        "    word_lists=[]\n",
        "    for i in range(len(sentence)):\n",
        "       w=sentence[i]\n",
        "       p_sample = sampling_prob(w)\n",
        "       threshold = np.random.random()\n",
        "       #print(threshold)\n",
        "       if p_sample > threshold:\n",
        "         # the word is kept\n",
        "         for n in range(2):\n",
        "                # look back\n",
        "            if (i-n-1)>=0:\n",
        "              word_lists.append([w] + [sentence[i-n-1]])\n",
        "                \n",
        "                # look forward\n",
        "            if (i+n+1)<len(sentence):\n",
        "              word_lists.append([w]+[sentence[i+n+1]])\n",
        "       else:\n",
        "         # the word is dropped\n",
        "         i+=1\n",
        "    return word_lists\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v5XjmO3X1mt"
      },
      "source": [
        "2.2.6Hyperparameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRYaiilEXwUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce458d7-6d96-4747-daa7-c825811fdccc"
      },
      "source": [
        "# Set hyperparameters\n",
        "window_size = 2\n",
        "embedding_size = 64\n",
        "vocabulary_size=len(V)\n",
        "print(len(V))\n",
        "# More hyperparameters\n",
        "learning_rate = 0.05\n",
        "epochs = 20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVkEI2cLSQG0"
      },
      "source": [
        "from modelss import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ8YNLGFYWaA"
      },
      "source": [
        "2.2.7 Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmAkeW2wSZsj"
      },
      "source": [
        "net = modelinput.Word2Vec(embed_size=embedding_size, vocab_size=vocabulary_size)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "net = net.to(device)\n",
        "\n",
        "W1 = net.input.weight\n",
        "W2 = net.output.weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE3ZW3osZNS4"
      },
      "source": [
        "2.2.8loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzrBKuWxYT2q"
      },
      "source": [
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8NY0_AZmyXP"
      },
      "source": [
        "2.2.9training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34eGdvHtZLmR",
        "outputId": "09100ff1-9bba-4f45-a924-447f14a7f33d"
      },
      "source": [
        "# load initial weights\n",
        "window_size = 2\n",
        "embedding_size = 64\n",
        "losses = [torch.tensor(1., device=device)]\n",
        "#losses.append(1)\n",
        "losses_mean=np.mean([tensor.cpu() for tensor in losses])\n",
        "def train():\n",
        "  \n",
        "  print(\"Training started\")\n",
        "\n",
        "train()\n",
        "\n",
        "for epo in range(epochs):\n",
        "  #while losses_mean> 0.006:\n",
        "     losses_mean=np.mean([tensor.cpu() for tensor in losses])\n",
        "     #mean = torch.mean(torch.stack(losses))\n",
        "     #mean = mean.to(device)\n",
        "     print(\"Loss: \", losses_mean)\n",
        "     net.train() \n",
        "    \n",
        "     for i in range(len(new_list_new)):\n",
        "        # Define train procedure\n",
        "        # step1:Skip-Grams\n",
        "        sentence = new_list_new[i]\n",
        "        idx_pairs = get_target_context(sentence)\n",
        "        for target, context in idx_pairs:\n",
        "        # step2:target one-hot encoding\n",
        "           X = word_to_one_hot(target)\n",
        "           X = torch.tensor(X)\n",
        "           x1 = X[0]\n",
        "           x1 = x1.to(device)\n",
        "           #print(x1)\n",
        "        # step3:Word2Vec\n",
        "           y =net.forward(x1)\n",
        "        \n",
        "           Y = word_to_one_hot(context)\n",
        "           Y = Y[0]\n",
        "           y_ture = torch.tensor(Y)\n",
        "           y_ture = y_ture.to(device)\n",
        "        # step4:loss\n",
        "           loss = criterion(y,y_ture)\n",
        "           #print(loss)\n",
        "           losses.append(loss.data)\n",
        "           losses.pop(0)\n",
        "           optimizer.zero_grad()\n",
        "           loss.backward()\n",
        "           optimizer.step()\n",
        "          \n",
        "        # step5:Backprop to update model parameters \n",
        "   \n",
        "           \n",
        "print(\"Training finished\")  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training started\n",
            "Loss:  1.0\n",
            "Loss:  0.004583854\n",
            "Loss:  0.0037243392\n",
            "Loss:  0.0030036597\n",
            "Loss:  0.0025144923\n",
            "Loss:  0.0022206428\n",
            "Loss:  0.0020977918\n",
            "Loss:  0.0020489437\n",
            "Loss:  0.002021249\n",
            "Loss:  0.002006018\n",
            "Loss:  0.0019953956\n",
            "Loss:  0.0019873697\n",
            "Loss:  0.0019809518\n",
            "Loss:  0.0019757247\n",
            "Loss:  0.0019726458\n",
            "Loss:  0.0019698825\n",
            "Loss:  0.0019677524\n",
            "Loss:  0.0019656494\n",
            "Loss:  0.0019642625\n",
            "Loss:  0.0019628925\n",
            "Training finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5r4kwATm5rR"
      },
      "source": [
        "Weight3=[]\n",
        "for i in range(len(V)-1):\n",
        "  weight3=[]\n",
        "  w=W1[i]\n",
        "  for y in range(embedding_size):\n",
        "    wei=w[y].item()\n",
        "    weight3.append(wei)\n",
        "  Weight3.append(weight3)\n",
        "    \n",
        "\n",
        "V2 = dict(zip(V, Weight3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBRDKXXlm9hU",
        "outputId": "652c78e2-2b7e-433a-fd2d-c9269cb933ed"
      },
      "source": [
        "sentence_padding =[]\n",
        "pad_idx = 0\n",
        "padding_standard = max(new_list_new, key=len,default='')\n",
        "\n",
        "#padding the sentence to the same length\n",
        "for i in range(len(new_list_new)):\n",
        "  temp_sentence = list()\n",
        "  temp = new_list_new[i]\n",
        "  while len(temp) < len(padding_standard):\n",
        "      temp.insert(len(temp), pad_idx)\n",
        "  sentence_padding.append(temp) \n",
        "\n",
        "#make sentences to the same size matrix using word embedding expression\n",
        "sentence_train=[]\n",
        "for i in range(len(sentence_padding)):\n",
        "  temp_sentence = list()\n",
        "  temp = new_list_new[i]\n",
        "  for word in temp:\n",
        "    if word in V2.keys():\n",
        "      temp_sentence.append(V2[word])\n",
        "    else:\n",
        "      temp_sentence.append(np.zeros(embedding_size))\n",
        "  sentence_train.append(temp_sentence)\n",
        "\n",
        "print(np.shape(sentence_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1100, 219, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHriSHLZnBSx"
      },
      "source": [
        "sentence_train3=torch.tensor(sentence_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofKWY_L6BP6O"
      },
      "source": [
        "We create an instance of our CNN class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6JikZ1znMAP"
      },
      "source": [
        "from modelinput import CNN\n",
        "EMBEDDING_DIM = embedding_size \n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [2,3,4]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = CNN(EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRe4U2MWBt8B"
      },
      "source": [
        "Train the Model : The method of training is same as the previous one. We can initialize the values of optimizer and criterion (loss function)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxd1bLkynTkd"
      },
      "source": [
        "optimizer1 = optim.Adam(model.parameters())\n",
        "\n",
        "criterion1 = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion1 = criterion1.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8calTXccnxTt"
      },
      "source": [
        "Apply the old classifer to the new data and print accuracy: We import a package called 'binary_accuracy' to calculate the accuracy. It returns accuracy per batch. For instance if 7/10 are correct repsonses, the output will be 0.7. Further, we define a function \"evaluate(model)\" for training our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMqO473XnYwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03bea454-2be4-4d1d-b62c-004e91962afe"
      },
      "source": [
        "\n",
        "from modelinput import binary_accuracy\n",
        "sentence_train3=sentence_train3.to(device,dtype=torch.float)\n",
        "Y_train = torch.tensor(y_train).to(device)\n",
        "def evaluate(model):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    predictions = model(sentence_train3).squeeze(1)\n",
        "            \n",
        "    loss = criterion1(predictions, Y_train.float())\n",
        "            \n",
        "    acc = binary_accuracy(predictions, Y_train)\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss, epoch_acc \n",
        "\n",
        "model.load_state_dict(torch.load('/content/CNNweight.pt'))\n",
        "test_loss, test_acc = evaluate(model)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.739 | Test Acc: 52.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8MW7hFjuH90"
      },
      "source": [
        "retrain the model and print new accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wfAeCxOnvQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b96e7c3-6010-4dc6-df22-8c27f56f61d5"
      },
      "source": [
        "\n",
        "N_EPOCHS = 20\n",
        "sentence_train3=sentence_train3.to(device,dtype=torch.float)\n",
        "#train_iterator = iter(sentence_train1)\n",
        "#best_valid_loss = float('inf')\n",
        "Y_train = torch.tensor(y_train).to(device)\n",
        "for epoch in range(N_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "  \n",
        "    optimizer1.zero_grad()\n",
        "\n",
        "    predictions = model.forward(sentence_train3).squeeze(1)    \n",
        "    loss1 = criterion1(predictions, Y_train.float())\n",
        "        \n",
        "    acc = binary_accuracy(predictions, Y_train)\n",
        "\n",
        "    loss1.backward()    \n",
        "    optimizer1.step()\n",
        "        \n",
        "    epoch_loss += loss1.item()\n",
        "    epoch_acc += acc.item()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    print(f'\\tTrain Loss: {loss1:.3f} | Train Acc: {acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.773 | Train Acc: 53.18%\n",
            "\tTrain Loss: 0.760 | Train Acc: 52.91%\n",
            "\tTrain Loss: 0.728 | Train Acc: 57.27%\n",
            "\tTrain Loss: 0.716 | Train Acc: 57.00%\n",
            "\tTrain Loss: 0.692 | Train Acc: 58.27%\n",
            "\tTrain Loss: 0.655 | Train Acc: 62.18%\n",
            "\tTrain Loss: 0.649 | Train Acc: 62.00%\n",
            "\tTrain Loss: 0.631 | Train Acc: 65.00%\n",
            "\tTrain Loss: 0.624 | Train Acc: 66.45%\n",
            "\tTrain Loss: 0.603 | Train Acc: 65.73%\n",
            "\tTrain Loss: 0.591 | Train Acc: 70.64%\n",
            "\tTrain Loss: 0.569 | Train Acc: 70.91%\n",
            "\tTrain Loss: 0.547 | Train Acc: 72.91%\n",
            "\tTrain Loss: 0.546 | Train Acc: 73.00%\n",
            "\tTrain Loss: 0.553 | Train Acc: 73.18%\n",
            "\tTrain Loss: 0.525 | Train Acc: 74.91%\n",
            "\tTrain Loss: 0.502 | Train Acc: 75.91%\n",
            "\tTrain Loss: 0.510 | Train Acc: 76.09%\n",
            "\tTrain Loss: 0.495 | Train Acc: 78.45%\n",
            "\tTrain Loss: 0.472 | Train Acc: 80.09%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-8MgMNwUUCe"
      },
      "source": [
        "Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EtF3YmuOBJO"
      },
      "source": [
        "import torch.nn as nn\n",
        "import copy\n",
        "\n",
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W79Re4TgOEbF"
      },
      "source": [
        "import math,copy\n",
        "#doing the position encoding first\n",
        "def positionalencoding1d(d_model, length):\n",
        "   \n",
        "    if d_model % 2 != 0:\n",
        "        raise ValueError(\"Cannot use sin/cos positional encoding with \"\n",
        "                         \"odd dim (got dim={:d})\".format(d_model))\n",
        "    pe = torch.zeros(length, d_model)\n",
        "    position = torch.arange(0, length).unsqueeze(1)\n",
        "    div_term = torch.exp((torch.arange(0, d_model, 2, dtype=torch.float) *\n",
        "                         -(math.log(10000.0) / d_model)))\n",
        "    pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
        "\n",
        "    return pe\n",
        "\n",
        "\n",
        "posit = positionalencoding1d(64,219) # the shape of one padding sentence\n",
        "posit = torch.tensor(posit,device=device)\n",
        "\n",
        "AttInput=torch.empty(np.shape(sentence_train3))\n",
        "\n",
        "for i in range(len(sentence_train3)):\n",
        "   tar =sentence_train3[i]\n",
        "   AttInput[i]= tar+posit\n",
        "Input = AttInput[0:100,]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3fvgBYaOHVP",
        "outputId": "a2f04551-b5b9-4e73-da14-a6aa1ca6b01e"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "SRC_VOCAB=1\n",
        "N_CLASS=1\n",
        "D_MODEL=embedding_size\n",
        "D_FF=1024\n",
        "N = 6\n",
        "H=8\n",
        "DROP_OUT=0.1\n",
        "model2 = modelinput.make_model(SRC_VOCAB,N,D_MODEL,D_FF,H,DROP_OUT, N_CLASS)\n",
        "model2 = model2.to(device)\n",
        "lr=0.005\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(),lr)\n",
        "N_EPOCHS = 10\n",
        "for epoch in range(N_EPOCHS):\n",
        "    epoch_loss2 = 0\n",
        "    epoch_acc2 = 0   \n",
        "  \n",
        "    optimizer2.zero_grad()\n",
        "\n",
        "    x = Input.to(device)\n",
        "    y = torch.tensor(y_train[0:100], dtype=torch.long, device=device)\n",
        "    y = y.unsqueeze(1)\n",
        "    \n",
        "    output = model2(x, None)\n",
        "    loss2 = criterion2(output,y)\n",
        "     \n",
        "\n",
        "    loss2.backward()    \n",
        "    optimizer2.step()\n",
        "        \n",
        "    epoch_loss2 += loss2.item()\n",
        "   \n",
        "    print(f'\\tTrain Loss: {loss2:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 5.390\n",
            "\tTrain Loss: 5.379\n",
            "\tTrain Loss: 5.375\n",
            "\tTrain Loss: 5.070\n",
            "\tTrain Loss: 5.299\n",
            "\tTrain Loss: 4.967\n",
            "\tTrain Loss: 4.964\n",
            "\tTrain Loss: 4.869\n",
            "\tTrain Loss: 4.852\n",
            "\tTrain Loss: 4.760\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}